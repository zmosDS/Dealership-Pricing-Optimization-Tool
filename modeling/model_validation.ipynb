{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9b7c727-bcc4-452d-883d-809762049808",
   "metadata": {},
   "source": [
    "# Model Validation\n",
    " \n",
    "### Objective:\n",
    "The objective of this notebook is to validate the performance of the LightGBM model on new data collected nearly a month after the original training data. The goal is to assess the model’s ability to predict car prices accurately amidst market fluctuations and determine its suitability as a vehicle value estimation tool.\n",
    "\n",
    "### Summary:\n",
    "In this notebook, the LightGBM model, originally trained on data from July 26th, was validated using new data from August 16th. The validation process involved scaling the new data to match the original training features and comparing model performance metrics between the two datasets. Despite a month of market changes, the LightGBM model maintained a robust predictive accuracy, showing slight variations in error metrics compared to the original data.\n",
    "\n",
    "#### **Key Findings**:\n",
    "- **Mean Absolute Error (MAE)**:\n",
    "  - Original Data (July 26th): `$1,609.03`\n",
    "  - Validation Data (August 16th): `$1,805.08`\n",
    "  - **Comparison**: The MAE increased by `$196.05`, reflecting slight degradation in model performance due to market fluctuations.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Mean Squared Error (MSE)**:\n",
    "  - Original Data (July 26th): `7,441,905`\n",
    "  - Validation Data (August 16th): `8,084,573`\n",
    "  - **Comparison**: The MSE showed a slight increase relative to the typical MSE score. \n",
    "\n",
    "<br>\n",
    "\n",
    "- **R² Score**:\n",
    "  - Original Data (July 26th): `0.9573`\n",
    "  - Validation Data (August 16th): `0.9527`\n",
    "  - **Comparison**: The R² score only marginally dropped, signifying that the model retained most of its explanatory power even with the newer data.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Data Set Size Consideration:**\n",
    "  - The validation set consisted of `9,229` samples, compared to `66,282` for training and `16,571` for testing in the original data. The smaller size of the validation set could contribute to higher variability in performance metrics, as it may not fully capture the range of conditions seen in the larger training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3556cdec-e94c-4a12-83fa-f4332431e9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary libraries\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24c4de4-9787-4435-a95a-885269d770fc",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99f7fc2-d24e-45bc-ac53-5a1a31616855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model and scaler loaded\n"
     ]
    }
   ],
   "source": [
    "# Load final model and final scaler\n",
    "final_model = joblib.load('final_model.pkl')\n",
    "final_scaler = joblib.load('final_scaler.pkl')\n",
    "\n",
    "print('Final model and scaler loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0412a0-0fde-4666-8893-3256252ecd57",
   "metadata": {},
   "source": [
    "### Load and Process Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0777f9e9-0ef4-49b7-8b63-3eb59ea17b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded & processed\n",
      "\n",
      "Validation Data Row and Column Count: (9229, 11)\n",
      "\n",
      "Validation Data Summary Statistics:\n",
      "         Year     Price   Mileage\n",
      "count  9229.0    9229.0    9229.0\n",
      "mean   2019.9   26628.8   55274.0\n",
      "std       3.0   13067.6   39231.3\n",
      "min    2010.0    2950.0    1002.0\n",
      "25%    2018.0   17998.0   24565.0\n",
      "50%    2021.0   23990.0   47128.0\n",
      "75%    2022.0   31702.0   78890.0\n",
      "max    2024.0  109890.0  270964.0\n"
     ]
    }
   ],
   "source": [
    "# Load validation data\n",
    "df_validation = pd.read_csv('cleaned_data_aug_16th.csv') \n",
    "\n",
    "# Define validation features and categorical features\n",
    "features = ['Year', 'Model', 'State', 'Mileage', 'Trim', 'Make', 'Body Style']\n",
    "cat_features = ['Model', 'State', 'Trim', 'Make', 'Body Style']\n",
    "\n",
    "# Format non-numerical columns as 'category'\n",
    "df_validation[cat_features] = df_validation[cat_features].astype('category')\n",
    "\n",
    "# Scale and format numerical features with scaler\n",
    "X_validation = df_validation[features].copy()\n",
    "X_validation[['Year', 'Mileage']] = final_scaler.transform(X_validation[['Year', 'Mileage']])\n",
    "X_validation[['Year', 'Mileage']] = X_validation[['Year', 'Mileage']].astype('float64')\n",
    "\n",
    "# Define validation target \n",
    "y_validation = df_validation['Price'].values\n",
    "\n",
    "# Print validation summary statistics\n",
    "print('Data loaded & processed\\n')\n",
    "print('Validation Data Row and Column Count:', df_validation.shape)\n",
    "print('\\nValidation Data Summary Statistics:')\n",
    "print(round(df_validation.describe(),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef28a643-fdfa-48ad-9483-e2802b7bbc6b",
   "metadata": {},
   "source": [
    "## Final Model on Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8939277e-7cd4-4785-b9a2-e7afb26ca27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mOptimized LightGBM Regressor Performance on Validation Data from 8/15:\u001b[0m\n",
      "Mean Absolute Error (MAE): $ 1,805.08\n",
      "Mean Squared Error  (MSE): 8,084,573\n",
      "R² Score             (R²): 0.9527\n",
      "\n",
      "\u001b[1mOptimized LightGBM Regressor Performance on Original Data from 7/26:\u001b[0m\n",
      "Mean Absolute Error (MAE): $ 1,609.03\n",
      "Mean Squared Error  (MSE): 7,441,905\n",
      "R² Score             (R²): 0.9573\n",
      "\n",
      "\u001b[1mPreliminary LightGBM Regressor Performance on Original Data from 7/26:\u001b[0m\n",
      "Mean Absolute Error (MAE): $ 1,695.51\n",
      "Mean Squared Error  (MSE): 8,147,484\n",
      "R² Score             (R²): 0.9532\n"
     ]
    }
   ],
   "source": [
    "# Predict validation data using final model\n",
    "pred_final = final_model.predict(X_validation)\n",
    "\n",
    "# Print validation data performance\n",
    "print('\\n\\033[1mOptimized LightGBM Regressor Performance on Validation Data from 8/15:\\033[0m')\n",
    "print(f'Mean Absolute Error (MAE): $ {round(metrics.mean_absolute_error(y_validation, pred_final), 2):,}')\n",
    "print(f'Mean Squared Error  (MSE): {int(round(metrics.mean_squared_error(y_validation, pred_final))):,}')\n",
    "print(f'R² Score             (R²): {round(metrics.r2_score(y_validation, pred_final), 4)}')\n",
    "\n",
    "# Print optimized lightgbm model on original data performance\n",
    "print('\\n\\033[1mOptimized LightGBM Regressor Performance on Original Data from 7/26:\\033[0m')\n",
    "print('Mean Absolute Error (MAE): $ 1,609.03')\n",
    "print('Mean Squared Error  (MSE): 7,441,905')\n",
    "print('R² Score             (R²): 0.9573')\n",
    "\n",
    "# Print preliminary lightgbm model on original data performance\n",
    "print('\\n\\033[1mPreliminary LightGBM Regressor Performance on Original Data from 7/26:\\033[0m')\n",
    "print('Mean Absolute Error (MAE): $ 1,695.51')\n",
    "print('Mean Squared Error  (MSE): 8,147,484')\n",
    "print('R² Score             (R²): 0.9532')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dbca2f-59d3-47df-8ac3-99a39ce39f4c",
   "metadata": {},
   "source": [
    "## **Conclusion**:\n",
    "The LightGBM model demonstrated strong resilience to market fluctuations, retaining robust predictive power with only minor increases in error metrics. The performance on validation data remains within an acceptable range, indicating that the model is suitable for continued use in car price prediction for dealerships. Regular model updates with fresh data will help maintain accuracy over time, especially in dynamic market conditions. The results validate the LightGBM model as an effective tool for optimizing vehicle pricing strategies based on historical data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
