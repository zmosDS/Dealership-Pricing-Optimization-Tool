{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f57bc1d-78d2-4e24-a591-439a6e6848ce",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Findings\n",
    "- **Random Forest:**",
    "  - **Mean Absolute Error (MAE):** 1,824.63\n",
    "  - **Mean Squared Error  (MSE):** 8,395,572.97\n",
    "  - **R2 Score             (R2):** 0.9515\n",
    "  - **Performance Summary:** Random Forest outperformed the other models overall, demonstrating the lowest MAE and MSE, indicating higher accuracy and better generalization.\n",
    "\n",
    "\n",
    "- **XGBoost:**",
    "  - **Mean Absolute Error (MAE):** 2,216.44\n",
    "  - **Mean Squared Error  (MSE):** 10,367,387.06\n",
    "  - **R2 Score             (R2):** 0.9402\n",
    "  - **Performance Summary:** XGBoost showed competitive performance with a slightly lower R2 score compared to Random Forest. However, it is known for responding well to hyperparameter tuning, which could potentially improve its performance.\n",
    "\n",
    "### Conclusion\n",
    "The Random Forest model had the best overall performance, with the lowest error metrics and the highest R2 score, making it a strong candidate for predicting car prices. However, the XGBoost model, despite slightly higher error metrics, demonstrated a competitive R2 score, suggesting it captures a substantial amount of variance. Given XGBoostâ€™s potential for significant improvements through hyperparameter tuning, I have decided to move forward with optimizing both the Random Forest and XGBoost models. The goal is to achieve the highest possible predictive performance by fine-tuning these models and comparing their performance post-optimization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0145597c-3fe3-44c4-a81f-286a4a8c93f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "from sklearnex import patch_sklearn \n",
    "patch_sklearn()\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, LassoCV, RidgeCV\n",
    "from sklearn import metrics, svm, preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401134f6-75a7-4c95-888e-2de895520592",
   "metadata": {},
   "source": [
    "## Processing Data\n",
    "#### 80% test / 20% train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99ae23d-10c3-40a1-a700-95a7c0e1d759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed\n"
     ]
    }
   ],
   "source": [
    "data_path = Path('path_name')\n",
    "car_data_df = pd.read_csv(data_path / 'car_data_cleaned.csv')\n",
    "\n",
    "car_data_df.drop(columns=['Listing ID'], inplace=True) # Listing id's are irrelevant\n",
    "car_data_df.drop(columns=['Stock Type'], inplace=True) # All stock type is 'used' \n",
    "\n",
    "seven_features = ['Year', 'Model', 'State', 'Mileage', 'Trim', 'Make', 'Body Style']\n",
    "\n",
    "X = pd.get_dummies(car_data_df[seven_features], drop_first=False).values # one-hot encodes categorical columns\n",
    "y = car_data_df['Price'].values.reshape(-1,1)\n",
    "\n",
    "column_names = pd.get_dummies(car_data_df[seven_features], drop_first=False) # fixes numpy array error\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=column_names.columns) #convert back to DataFrame to maintain column names / use x2 otherwise error \n",
    "\n",
    "# splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=.2, random_state=1)\n",
    "\n",
    "print('Data processed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d2e082-4b19-40d1-8878-23eff7535fa2",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5984a48-e5aa-496f-8b88-e24b0365da1d",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "#### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104af758-be8e-4425-9466-ac0decf1d6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mLinear Regression Performance:\u001b[0m\n",
      "Mean Absolute Error (MAE):  1.2229085108027732e+138\n",
      "Mean Squared Error  (MSE):  1.0536039679942167e+280\n",
      "R2 Score             (R2):  -6.081423121374969e+271\n",
      "5.2 seconds to execute.",
      "\n",
      "\n",
      "intercept  9.779237449219169e+120\n",
      "                    Predictor    coefficient\n",
      "0                        Year   4.388868e+03\n",
      "1                     Mileage  -3.661332e+03\n",
      "2                  Model_370z  -1.794623e+14\n",
      "3               Model_4runner   2.065697e+14\n",
      "4                    Model_86   1.473291e+13\n",
      "..                        ...            ...\n",
      "975  Body Style_passenger van -3.652301e+118\n",
      "976   Body Style_pickup truck -1.247812e+119\n",
      "977          Body Style_sedan -1.292097e+119\n",
      "978            Body Style_suv -1.627791e+119\n",
      "979          Body Style_wagon -2.659945e+118\n",
      "\n",
      "[980 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Train model\n",
    "Linear_model = LinearRegression()\n",
    "Linear_model.fit(X_train,y_train.ravel())\n",
    "pred_linear = Linear_model.predict(X_test)\n",
    "\n",
    "# Print performance\n",
    "print(\"\\033[1mLinear Regression Performance:\\033[0m\")\n",
    "print(\"Mean Absolute Error (MAE): \", metrics.mean_absolute_error(y_test, pred_linear))\n",
    "print(\"Mean Squared Error  (MSE): \", metrics.mean_squared_error(y_test, pred_linear))\n",
    "print(\"R2 Score             (R2): \", metrics.r2_score(y_test, pred_linear))\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = (end_time - start_time)\n",
    "print(f\"{elapsed_time:.1f} seconds to execute.\")\n",
    "print('\\n')\n",
    "\n",
    "# Print coefficients\n",
    "print('intercept ', Linear_model.intercept_)\n",
    "print(pd.DataFrame({'Predictor': X_scaled.columns, 'coefficient': Linear_model.coef_}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137377e1-c3fa-47a4-8e26-00c317aa80f2",
   "metadata": {},
   "source": [
    "## Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc330c94-f87e-4904-84f0-61e9bcc539e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRandom Forest Regression Performance:\u001b[0m\n",
      "Mean Absolute Error (MAE):  1828.4619247116739\n",
      "Mean Squared Error  (MSE):  8429433.705244176\n",
      "R2 Score             (R2):  0.9513451404964234\n",
      "61.0 seconds to execute.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Train model\n",
    "RF_model = RandomForestRegressor(n_jobs=-1)\n",
    "RF_model.fit(X_train,y_train.ravel())\n",
    "pred_RF = RF_model.predict(X_test)\n",
    "\n",
    "# Print performance\n",
    "print(\"\\033[1mRandom Forest Regression Performance:\\033[0m\")\n",
    "print(\"Mean Absolute Error (MAE): \", metrics.mean_absolute_error(y_test, pred_RF))\n",
    "print(\"Mean Squared Error  (MSE): \", metrics.mean_squared_error(y_test, pred_RF))\n",
    "print(\"R2 Score             (R2): \", metrics.r2_score(y_test, pred_RF))\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = (end_time - start_time)\n",
    "print(f\"{elapsed_time:.1f} seconds to execute.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512922e5-811b-4dd5-ab1a-dd4375cb6ec0",
   "metadata": {},
   "source": [
    "## XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6a215f-7b58-4f3e-9fc4-08a23efcd425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mXGBoost Regression Performance:\u001b[0m\n",
      "Mean Absolute Error (MAE):  2216.44419821337\n",
      "Mean Squared Error  (MSE):  10367387.055782594\n",
      "R2 Score             (R2):  0.9401592350973133\n",
      "2.0 seconds to execute.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Train model\n",
    "XGBoost_model = xgb.XGBRegressor()\n",
    "XGBoost_model.fit(X_train, y_train.ravel())\n",
    "pred_XGBoost = XGBoost_model.predict(X_test)\n",
    "\n",
    "# Print performance\n",
    "print(\"\\033[1mXGBoost Regression Performance:\\033[0m\")\n",
    "print(\"Mean Absolute Error (MAE): \", metrics.mean_absolute_error(y_test, pred_XGBoost))\n",
    "print(\"Mean Squared Error  (MSE): \", metrics.mean_squared_error(y_test, pred_XGBoost))\n",
    "print(\"R2 Score             (R2): \", metrics.r2_score(y_test, pred_XGBoost))\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = (end_time - start_time)\n",
    "print(f\"{elapsed_time:.1f} seconds to execute.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bbfa06-2a41-4d1a-a3ec-cd8667ecab4b",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6799dc42-dfa0-4907-8116-75798f9367e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRidge Regression Performance:\u001b[0m\n",
      "Mean Absolute Error (MAE):  2565.9715533219355\n",
      "Mean Squared Error  (MSE):  15555801.976605577\n",
      "R2 Score             (R2):  0.9102116006717822\n",
      "32.6 seconds to execute.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Train model (using more accurate RidgeCV vs Ridge) \n",
    "Ridge_model = RidgeCV(alphas=np.logspace(-6, 6, 13), cv=5) #logspace finds the best alpha with ridgecv\n",
    "Ridge_model.fit(X_train,y_train.ravel())\n",
    "pred_Ridge = Ridge_model.predict(X_test)\n",
    "\n",
    "# Print performance\n",
    "print(\"\\033[1mRidge Regression Performance:\\033[0m\")\n",
    "print(\"Mean Absolute Error (MAE): \", metrics.mean_absolute_error(y_test, pred_Ridge))\n",
    "print(\"Mean Squared Error  (MSE): \", metrics.mean_squared_error(y_test, pred_Ridge))\n",
    "print(\"R2 Score             (R2): \", metrics.r2_score(y_test, pred_Ridge))\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = (end_time - start_time)\n",
    "print(f\"{elapsed_time:.1f} seconds to execute.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd15e958-d95f-4115-9713-9d01fd05cfa6",
   "metadata": {},
   "source": [
    "## Lasso Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dafa2d-bdb2-4ff6-954c-c9623356bfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mLasso Regression Performance:\u001b[0m\n",
      "Mean Absolute Error (MAE):  2563.41953317199\n",
      "Mean Squared Error  (MSE):  15539556.65403859\n",
      "R2 Score             (R2):  0.9103053689977132\n",
      "31.2 seconds to execute.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Train model\n",
    "Lasso_model = LassoCV(cv=5, random_state=1)\n",
    "Lasso_model.fit(X_train,y_train.ravel())\n",
    "pred_Lasso = Lasso_model.predict(X_test)\n",
    "\n",
    "print(\"\\033[1mLasso Regression Performance:\\033[0m\")\n",
    "print(\"Mean Absolute Error (MAE): \", metrics.mean_absolute_error(y_test, pred_Lasso))\n",
    "print(\"Mean Squared Error  (MSE): \", metrics.mean_squared_error(y_test, pred_Lasso))\n",
    "print(\"R2 Score             (R2): \", metrics.r2_score(y_test, pred_Lasso))\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = (end_time - start_time)\n",
    "print(f\"{elapsed_time:.1f} seconds to execute.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fd5ad6-6d59-4c1c-b9dc-57fc45606dcc",
   "metadata": {},
   "source": [
    "## Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f3fecf-f4bc-4474-8015-b4a3161b5528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSupport Vector Regression Performance:\u001b[0m\n",
      "Mean Absolute Error (MAE):  9320.233042386373\n",
      "Mean Squared Error  (MSE):  175549010.58708507\n",
      "R2 Score             (R2):  -0.013272391097010505\n",
      "59.7 seconds to execute.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Train model\n",
    "SVR_model = SVR()\n",
    "SVR_model.fit(X_train,y_train.ravel())\n",
    "pred_SVR = SVR_model.predict(X_test)\n",
    "\n",
    "print(\"\\033[1mSupport Vector Regression Performance:\\033[0m\")\n",
    "print(\"Mean Absolute Error (MAE): \", metrics.mean_absolute_error(y_test, pred_SVR))\n",
    "print(\"Mean Squared Error  (MSE): \", metrics.mean_squared_error(y_test, pred_SVR))\n",
    "print(\"R2 Score             (R2): \", metrics.r2_score(y_test, pred_SVR))\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = (end_time - start_time)\n",
    "print(f\"{elapsed_time:.1f} seconds to execute.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271fc137-9a8b-48c0-a0be-13c8c3739e93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
